{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":53666,"databundleVersionId":6589269,"sourceType":"competition"},{"sourceId":6507308,"sourceType":"datasetVersion","datasetId":3706667}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-02T08:15:32.271234Z","iopub.execute_input":"2023-12-02T08:15:32.271605Z","iopub.status.idle":"2023-12-02T08:15:32.695514Z","shell.execute_reply.started":"2023-12-02T08:15:32.271575Z","shell.execute_reply":"2023-12-02T08:15:32.694480Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2023-12-02T08:15:35.458244Z","iopub.execute_input":"2023-12-02T08:15:35.459195Z","iopub.status.idle":"2023-12-02T08:15:35.466459Z","shell.execute_reply.started":"2023-12-02T08:15:35.459135Z","shell.execute_reply":"2023-12-02T08:15:35.465146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pandas.api.types import is_datetime64_ns_dtype","metadata":{"execution":{"iopub.status.busy":"2023-12-02T08:17:41.713315Z","iopub.execute_input":"2023-12-02T08:17:41.713742Z","iopub.status.idle":"2023-12-02T08:17:41.719148Z","shell.execute_reply.started":"2023-12-02T08:17:41.713708Z","shell.execute_reply":"2023-12-02T08:17:41.717943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"path='/kaggle/input/zzzs-lightweight-training-dataset-target/Zzzs_train.parquet'\n","metadata":{"execution":{"iopub.status.busy":"2023-12-02T08:15:55.421929Z","iopub.execute_input":"2023-12-02T08:15:55.422299Z","iopub.status.idle":"2023-12-02T08:16:04.366061Z","shell.execute_reply.started":"2023-12-02T08:15:55.422270Z","shell.execute_reply":"2023-12-02T08:16:04.365143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"code","source":"@staticmethod\ndef reduce_mem_usage(df):\n  \n    \n    for col in df.columns:\n        col_type = df[col].dtype\n\n        if col_type != object and not is_datetime64_ns_dtype(df[col]) and not 'category':\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int32)  \n            else:\n                df[col] = df[col].astype(np.float16)\n        \n    return df","metadata":{"execution":{"iopub.status.busy":"2023-12-02T08:16:26.744228Z","iopub.execute_input":"2023-12-02T08:16:26.744608Z","iopub.status.idle":"2023-12-02T08:16:26.756561Z","shell.execute_reply.started":"2023-12-02T08:16:26.744575Z","shell.execute_reply":"2023-12-02T08:16:26.755686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def feature_programming(df):\n  \n    #timestamp\n    df['timestamp'] = pd.to_datetime(df['timestamp']).apply(lambda t: t.tz_localize(None))\n    df['hour']=df['timestamp'].dt.hour\n    \n    #timestamp\n    df['series_id'] = df['series_id'].astype('category')\n    df.sort_values(['timestamp'], inplace=True)\n    df.set_index('timestamp', inplace=True)\n \n\n    #1)perform shift\n    for i in [60, 360, 720, 3600]:\n    #sma as 0th basic feature\n        df['anglez_roll_'+str(i)]=df['anglez'].rolling(window=i,center=True).mean().bfill().ffill().astype('float16')\n        df['enmo_roll_'+str(i)]=df['enmo'].rolling(window=i,center=True).mean().bfill().ffill().astype('float16')\n    #2)perform difference\n    #first difference\n        df['anglez_momentum_'+str(i)]=(df['anglez']-df['anglez_roll_'+str(i)])\n        df['enmo_momentum_'+str(i)]=df['enmo']-df['enmo_roll_'+str(i)]\n        #for 1th order\n        #1st basic feature\n        df['ratio_ang_'+str(i)]=df['anglez_momentum_'+str(i)].div(df['anglez_roll_'+str(i)]).fillna(0).replace([np.inf,-np.inf],0).astype('float16')\n        df['ratio_enm_'+str(i)]=df['enmo_momentum_'+str(i)].div(df['enmo_roll_'+str(i)]).fillna(0).replace([np.inf,-np.inf],0).astype('float16')\n    \n        #denoise\n        df['anglez_max_'+str(i)]=df['anglez'].rolling(window=i).max().bfill().ffill().astype('float16')\n        df['anglez_min_'+str(i)]=df['anglez'].rolling(window=i).min().bfill().ffill().astype('float16')\n        df['enmo_max_'+str(i)]=df['enmo'].rolling(window=i).max().bfill().ffill().astype('float16')\n        df['enmo_min_'+str(i)]=df['enmo'].rolling(window=i).min().bfill().ffill().astype('float16')\n        \n        \n    \n    gc.collect()\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2023-11-21T01:34:26.507060Z","iopub.execute_input":"2023-11-21T01:34:26.507651Z","iopub.status.idle":"2023-11-21T01:34:26.527079Z","shell.execute_reply.started":"2023-11-21T01:34:26.507617Z","shell.execute_reply":"2023-11-21T01:34:26.526235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef feat_eng_by_id(idx，file):\n    \n    from warnings import simplefilter \n    simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n    \n    #分id读取\n    df  = pd.read_parquet(file, filters=[('series_id','=',idx)])\n    df['awake'] = df['awake'].astype(np.int8)\n    df = reduce_mem_usage(df)\n    df = feature_programming(df)\n    \n    \n    return df\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"series_id = pd.read_parquet('/kaggle/input/zzzs-lightweight-training-dataset-target/Zzzs_train.parquet', columns=['series_id'])\nseries_id = series_id.series_id.unique()\nseries_id = list(series_id)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T09:02:28.133041Z","iopub.execute_input":"2023-12-02T09:02:28.133487Z","iopub.status.idle":"2023-12-02T09:02:30.492859Z","shell.execute_reply.started":"2023-12-02T09:02:28.133455Z","shell.execute_reply":"2023-12-02T09:02:30.491780Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom joblib import Parallel, delayed\nfrom itertools import groupby\n\ntrain=Parallel(n_jobs=6)(delayed(feat_eng_by_id)(i)for i in serise_id)","metadata":{"execution":{"iopub.status.busy":"2023-12-02T08:55:30.388839Z","iopub.execute_input":"2023-12-02T08:55:30.389800Z","iopub.status.idle":"2023-12-02T08:55:30.396432Z","shell.execute_reply.started":"2023-12-02T08:55:30.389765Z","shell.execute_reply":"2023-12-02T08:55:30.395213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"execution":{"iopub.status.busy":"2023-11-20T17:18:27.671084Z","iopub.execute_input":"2023-11-20T17:18:27.671882Z","iopub.status.idle":"2023-11-20T17:30:13.963589Z","shell.execute_reply.started":"2023-11-20T17:18:27.671839Z","shell.execute_reply":"2023-11-20T17:30:13.962727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-11-20T17:31:24.525599Z","iopub.execute_input":"2023-11-20T17:31:24.525952Z","iopub.status.idle":"2023-11-20T17:31:24.588783Z","shell.execute_reply.started":"2023-11-20T17:31:24.525913Z","shell.execute_reply":"2023-11-20T17:31:24.587753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# model select","metadata":{}},{"cell_type":"code","source":"train.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ny='awake'","metadata":{"execution":{"iopub.status.busy":"2023-11-20T17:31:29.476210Z","iopub.execute_input":"2023-11-20T17:31:29.476615Z","iopub.status.idle":"2023-11-20T17:31:29.484331Z","shell.execute_reply.started":"2023-11-20T17:31:29.476579Z","shell.execute_reply":"2023-11-20T17:31:29.483359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# RF","metadata":{}},{"cell_type":"code","source":"import scipy\nimport cudf as cu\nfrom sklearn.ensemble import RandomForestClassifier \nRF = RandomForestClassifier(n_estimators=1000,\n                                    min_samples_leaf=300,\n                                    random_state=42,n_jobs=-1)\n\n\nimportances = RF.feature_importances_\n\nindices = np.argsort(importances)[::-1]\n\nfor f in range(train[X].shape[1]):\n    print(\"%2d) %-*s %f\" % (f + 1, 30, feat_labels[indices[f]], importances[indices[f]]))\n","metadata":{"execution":{"iopub.status.busy":"2023-11-20T17:31:33.282944Z","iopub.execute_input":"2023-11-20T17:31:33.283615Z","iopub.status.idle":"2023-11-20T17:31:38.953063Z","shell.execute_reply.started":"2023-11-20T17:31:33.283581Z","shell.execute_reply":"2023-11-20T17:31:38.952202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create a df to store feature‘s importance\n#feature_importance=pd.DataFrame({'feature':train.columns,'importance':select.feature_importance_})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# XGBoost -gpu","metadata":{}},{"cell_type":"code","source":"import xgboost as xgb\nfrom xgboost.sklearn import XGBClassifier\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.model_selection import GridSearchCV\n\n\nimport matplotlib.pylab as plt\n%matplotlib inline\nfrom matplotlib.pylab import rcParams\nrcParams['figure.figsize']=12,4\n\n\n#XGBoost models and cv\ndef modelfit(alg,x,y,useTrainCV=True,cv_folds=5,early_stopping_rounds=50):\n  #params:alg\n  if useTrainCV:\n    xgb_param=alg.get_xgb_params()\n    xgtrain=xgb.DMatrix(x.values,label=y.values)\n    cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n        metrics='auc', early_stopping_rounds=early_stopping_rounds)\n    alg.set_params(n_estimators=cvresult.shape[0])\n \n    #Fit the algorithm on the data\n  alg.fit(x,y,eval_metric='auc')\n \n#Predict training set:\n  dtrain_predictions = alg.predict(x)\n  dtrain_predprob = alg.predict_proba(x)[:,1]\n \n#Print model report:\n  print (\"\\nModel Report\")\n  print (\"Accuracy : %.4g\" % metrics.accuracy_score(y.values, dtrain_predictions))\n  print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(y, dtrain_predprob))\n \n  feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n  feat_imp.plot(kind='bar', title='Feature Importances')\n  plt.ylabel('Feature Importance Score')","metadata":{"execution":{"iopub.status.busy":"2023-11-20T17:31:43.525628Z","iopub.execute_input":"2023-11-20T17:31:43.526186Z","iopub.status.idle":"2023-11-20T17:31:43.704817Z","shell.execute_reply.started":"2023-11-20T17:31:43.526157Z","shell.execute_reply":"2023-11-20T17:31:43.703863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#learning rate and tree_based\n#initialization\n\nxgb=XGBClassifier(learning_rate=0.1,\n                   n_estimators=1000,\n                   max_depth=5,\n                   min_child_weight=1,\n                   gamma=0,\n                   subsample=0.8,\n                   colsample_bytree=0.8,\n                   objective='binary:logistic',\n                   nthread=4,\n                   scale_pos_weight=1,\n                   seed=42,\n                  gpu_id=0,\n                 tree_method=\"gpu_hist\")\n","metadata":{"execution":{"iopub.status.busy":"2023-11-20T17:31:47.775222Z","iopub.execute_input":"2023-11-20T17:31:47.775808Z","iopub.status.idle":"2023-11-20T17:31:47.781462Z","shell.execute_reply.started":"2023-11-20T17:31:47.775775Z","shell.execute_reply":"2023-11-20T17:31:47.780409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# lightgbm","metadata":{}},{"cell_type":"code","source":"!pip install  --upgrade pyarrow","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import lightgbm as lgb\nlgb_opt =  {\n    'num_leaves': 204,\n    'learning_rate': 0.076,\n    'random_state': 42,\n     'device’':'gpu', 'gpu_platform_id':0, 'gpu_device_id':0\n}\n\nlgb = lgb.LGBMClassifier(**lgb_opt)","metadata":{"execution":{"iopub.status.busy":"2023-11-20T17:31:55.197794Z","iopub.execute_input":"2023-11-20T17:31:55.198146Z","iopub.status.idle":"2023-11-20T17:31:56.101251Z","shell.execute_reply.started":"2023-11-20T17:31:55.198120Z","shell.execute_reply":"2023-11-20T17:31:56.100277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# stacking","metadata":{}},{"cell_type":"code","source":"!pip install mlxtend","metadata":{"execution":{"iopub.status.busy":"2023-11-20T17:32:23.280916Z","iopub.execute_input":"2023-11-20T17:32:23.281299Z","iopub.status.idle":"2023-11-20T17:32:35.859206Z","shell.execute_reply.started":"2023-11-20T17:32:23.281267Z","shell.execute_reply":"2023-11-20T17:32:35.858054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"git clone --recursive [https://github.com/dmlc/xgboost.git](https://github.com/dmlc/xgboost.git)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom mlxtend.classifier import StackingCVClassifier\nlr=LogisticRegression()\n\nsclf=StackingCVClassifier(classifiers=[RF,lgb,xgb],\n                         meta_classifier=lr,\n                         random_state=42)\n\n#output\nfor clf,label in zip([RF,lgb,xgb,sclf],['RF','Lgb','XGBoost','stackingClassifier']):\n    scores=cross_val_score(clf,train[X],train[y],cv=5,scoring='accuracy')\n    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n    ","metadata":{"execution":{"iopub.status.busy":"2023-11-20T17:32:40.703300Z","iopub.execute_input":"2023-11-20T17:32:40.704446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# output","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\nraw=test=pd.read_parquet('/kaggle/input/child-mind-institute-detect-sleep-states/test_series.parquet')\ntest=feature_programming(raw_test,delta_t=[30,90,120,360,480])\nX_test = test[X]\ny_test=test[y]\ntest[\"score\"] = sclf.predict_proba(X_test)[:,1]\ne\"]\n\ntest[\"not_awake\"] = 1-test[\"score\"]\n# exponential smoothing of the predictions\ntest[\"smooth\"] = test[\"not_awake\"].ewm(span = 100).mean()\n# re-binarize\ntest[\"smooth\"] = test[\"smooth\"].round()\n\n\ndef get_event(df):\n    lstCV = zip(df.series_id, df.smooth)\n    lstPOI = []\n    for (c, v), g in groupby(lstCV, lambda cv: \n                            (cv[0], cv[1]!=0 and not pd.isnull(cv[1]))):\n        llg = sum(1 for item in g)\n        if v is False: \n            lstPOI.extend([0]*llg)\n        else: \n            lstPOI.extend(['onset']+(llg-2)*[0]+['wakeup'] if llg > 1 else [0])\n    return lstPOI\n\ntest[\"event\"] = get_event(test)\n\n\nsample_submission = test.loc[test[\"event\"] != 0][[\"series_id\",\"step\",\"event\",\"score\"]].copy().reset_index(drop=True).reset_index(names=\"row_id\")\nsample_submission.to_csv('submission.csv', index=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}